use std::path::Path;
use std::sync::Arc;

/// Reset SIGPIPE to default behavior so piping (e.g. `oxid graph | dot`) exits cleanly
/// instead of panicking on broken pipe.
#[cfg(unix)]
fn reset_sigpipe() {
    unsafe {
        libc::signal(libc::SIGPIPE, libc::SIG_DFL);
    }
}

use anyhow::{bail, Context, Result};
use clap::{Parser, Subcommand};
use colored::Colorize;
use tracing_subscriber::EnvFilter;

mod config;
mod dag;
mod executor;
mod hcl;
mod output;
mod planner;
mod provider;
mod state;

use config::loader;
use executor::engine::ResourceEngine;
use provider::manager::ProviderManager;
use state::backend::StateBackend;
use state::models::{ResourceFilter, ResourceState};
use state::query::{execute_query, QueryFormat};
use state::sqlite::SqliteBackend;

/// oxid - Standalone infrastructure engine
#[derive(Parser)]
#[command(name = "oxid", version, about, long_about = None)]
struct Cli {
    /// Path to config directory or file (auto-detects .tf and .yaml)
    #[arg(short, long, default_value = ".")]
    config: String,

    /// Enable verbose logging
    #[arg(short, long)]
    verbose: bool,

    /// Working directory for .oxid state and cache
    #[arg(short, long, default_value = ".oxid")]
    working_dir: String,

    /// Maximum parallelism for resource operations
    #[arg(short, long, default_value = "10")]
    parallelism: usize,

    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Initialize project — download providers, create state database
    Init,

    /// Show execution plan (resource-level create/update/delete)
    Plan {
        /// Plan only specific resource address(es)
        #[arg(short, long)]
        target: Vec<String>,
    },

    /// Apply infrastructure changes with resource-level parallelism
    Apply {
        /// Apply only specific resource address(es)
        #[arg(short, long)]
        target: Vec<String>,

        /// Skip confirmation prompt
        #[arg(long)]
        auto_approve: bool,
    },

    /// Destroy infrastructure in reverse dependency order
    Destroy {
        /// Destroy only specific resource address(es)
        #[arg(short, long)]
        target: Vec<String>,

        /// Skip confirmation prompt
        #[arg(long)]
        auto_approve: bool,
    },

    /// Manage state
    State {
        #[command(subcommand)]
        command: StateCommands,
    },

    /// Import existing infrastructure
    Import {
        #[command(subcommand)]
        command: ImportCommands,
    },

    /// Run a SQL query against the state database
    Query {
        /// SQL query to execute (SELECT only)
        sql: String,

        /// Output format: table, json, csv
        #[arg(short, long, default_value = "table")]
        format: String,
    },

    /// Manage workspaces
    Workspace {
        #[command(subcommand)]
        command: WorkspaceCommands,
    },

    /// Show dependency graph as DOT
    Graph {
        /// Graph type: resource or module
        #[arg(short = 'T', long, default_value = "resource")]
        graph_type: String,
    },

    /// List providers and their versions
    Providers,

    /// Detect drift between state and real infrastructure
    Drift {
        /// Refresh state from providers before comparing
        #[arg(long)]
        refresh: bool,
    },

    /// Validate configuration without running anything
    Validate,
}

#[derive(Subcommand)]
enum StateCommands {
    /// List all resources in state
    List {
        /// Filter by resource type (e.g. aws_vpc)
        #[arg(long)]
        filter: Option<String>,
    },

    /// Show details for a specific resource
    Show {
        /// Resource address (e.g. aws_instance.web)
        address: String,
    },

    /// Remove a resource from state without destroying it
    Rm {
        /// Resource address to remove
        address: String,
    },

    /// Move a resource to a new address in state
    Mv {
        /// Source resource address
        source: String,
        /// Destination resource address
        destination: String,
    },
}

#[derive(Subcommand)]
enum ImportCommands {
    /// Import from a .tfstate file
    Tfstate {
        /// Path to .tfstate file
        path: String,
    },

    /// Import a single resource by provider ID
    Resource {
        /// Resource address (e.g. aws_instance.web)
        address: String,
        /// Provider resource ID
        id: String,
    },
}

#[derive(Subcommand)]
enum WorkspaceCommands {
    /// List all workspaces
    List,
    /// Create a new workspace
    New {
        /// Workspace name
        name: String,
    },
    /// Select a workspace
    Select {
        /// Workspace name
        name: String,
    },
    /// Delete a workspace
    Delete {
        /// Workspace name
        name: String,
    },
}

const DEFAULT_WORKSPACE: &str = "default";

#[tokio::main]
async fn main() -> Result<()> {
    #[cfg(unix)]
    reset_sigpipe();

    let cli = Cli::parse();

    let filter = if cli.verbose {
        EnvFilter::new("debug")
    } else {
        EnvFilter::new("warn")
    };
    tracing_subscriber::fmt()
        .with_env_filter(filter)
        .with_target(false)
        .init();

    match cli.command {
        Commands::Init => cmd_init(&cli).await,
        Commands::Plan { ref target } => cmd_plan(&cli, target).await,
        Commands::Apply {
            ref target,
            auto_approve,
        } => cmd_apply(&cli, target, auto_approve).await,
        Commands::Destroy {
            ref target,
            auto_approve,
        } => cmd_destroy(&cli, target, auto_approve).await,
        Commands::State { ref command } => cmd_state(&cli, command).await,
        Commands::Import { ref command } => cmd_import(&cli, command).await,
        Commands::Query {
            ref sql,
            ref format,
        } => cmd_query(&cli, sql, format).await,
        Commands::Workspace { ref command } => cmd_workspace(&cli, command).await,
        Commands::Graph { ref graph_type } => cmd_graph(&cli, graph_type).await,
        Commands::Providers => cmd_providers(&cli).await,
        Commands::Drift { refresh } => cmd_drift(&cli, refresh).await,
        Commands::Validate => cmd_validate(&cli).await,
    }
}

// ─── Helpers ─────────────────────────────────────────────────────────────────

fn open_backend(working_dir: &str) -> Result<SqliteBackend> {
    let db_path = format!("{}/oxid.db", working_dir);
    SqliteBackend::open(&db_path)
}

fn provider_manager(working_dir: &str) -> ProviderManager {
    let cache_dir = std::path::PathBuf::from(format!("{}/providers", working_dir));
    ProviderManager::new(cache_dir)
}

// ─── Commands ────────────────────────────────────────────────────────────────

async fn cmd_init(cli: &Cli) -> Result<()> {
    let config_path = Path::new(&cli.config);
    let working_dir = &cli.working_dir;

    // Create working directory structure
    std::fs::create_dir_all(working_dir)?;
    std::fs::create_dir_all(format!("{}/providers", working_dir))?;

    // Initialize state database
    let backend = open_backend(working_dir)?;
    backend.initialize().await?;

    // Create default workspace
    match backend.get_workspace(DEFAULT_WORKSPACE).await? {
        Some(_) => {}
        None => {
            backend.create_workspace(DEFAULT_WORKSPACE).await?;
        }
    }

    // Load config and download providers if config exists
    let mode = loader::detect_mode(config_path);
    if mode != loader::ConfigMode::Yaml || config_path.exists() {
        match loader::load_workspace(config_path) {
            Ok(workspace) => {
                let pm = provider_manager(working_dir);
                let mut downloaded = 0;
                for provider in &workspace.providers {
                    let version = provider.version_constraint.as_deref().unwrap_or(">= 0.0.0");
                    tracing::info!(
                        provider = %provider.source,
                        version = %version,
                        "Downloading provider"
                    );
                    match pm.ensure_provider(&provider.source, version).await {
                        Ok(path) => {
                            println!(
                                "  {} {} ({})",
                                "+".green(),
                                provider.source.bold(),
                                path.display()
                            );
                            downloaded += 1;
                        }
                        Err(e) => {
                            println!("  {} {} — {}", "!".yellow(), provider.source.bold(), e);
                        }
                    }
                }
                if downloaded > 0 {
                    println!();
                    println!(
                        "{} Downloaded {} provider(s).",
                        "✓".green().bold(),
                        downloaded
                    );
                }
            }
            Err(_) => {
                // No config found yet — that's fine for init
            }
        }
    }

    output::formatter::print_success("Project initialized successfully.");
    Ok(())
}

async fn cmd_plan(cli: &Cli, targets: &[String]) -> Result<()> {
    let workspace = loader::load_workspace(Path::new(&cli.config))?;
    let backend = open_backend(&cli.working_dir)?;
    backend.initialize().await?;

    let ws = backend
        .get_workspace(DEFAULT_WORKSPACE)
        .await?
        .context("No default workspace. Run 'oxid init' first.")?;

    let pm = Arc::new(provider_manager(&cli.working_dir));
    let engine = ResourceEngine::new(pm, cli.parallelism);

    let plan = engine.plan(&workspace, &backend, &ws.id).await?;
    engine.shutdown().await?;

    output::formatter::print_resource_plan(&plan, targets);
    Ok(())
}

async fn cmd_apply(cli: &Cli, targets: &[String], auto_approve: bool) -> Result<()> {
    let workspace = loader::load_workspace(Path::new(&cli.config))?;
    let backend = open_backend(&cli.working_dir)?;
    backend.initialize().await?;

    let ws = backend
        .get_workspace(DEFAULT_WORKSPACE)
        .await?
        .context("No default workspace. Run 'oxid init' first.")?;

    let pm = Arc::new(provider_manager(&cli.working_dir));
    let engine = ResourceEngine::new(pm, cli.parallelism);

    // Plan first
    let plan = engine.plan(&workspace, &backend, &ws.id).await?;
    output::formatter::print_resource_plan(&plan, targets);

    if plan.creates == 0 && plan.updates == 0 && plan.deletes == 0 && plan.replaces == 0 {
        println!("\n{}", "No changes. Infrastructure is up-to-date.".green());
        engine.shutdown().await?;
        return Ok(());
    }

    // Confirm
    if !auto_approve {
        println!(
            "\nDo you want to perform these actions? Only '{}' will be accepted.",
            "yes".bold()
        );
        print!("  Enter a value: ");
        use std::io::Write;
        std::io::stdout().flush()?;
        let mut input = String::new();
        std::io::stdin().read_line(&mut input)?;
        if input.trim() != "yes" {
            println!("\n{}", "Apply cancelled.".yellow());
            engine.shutdown().await?;
            return Ok(());
        }
    }

    // Record run
    let run_id = backend
        .start_run(
            &ws.id,
            "apply",
            (plan.creates + plan.updates + plan.deletes) as i32,
        )
        .await?;

    // Apply
    let backend_arc: Arc<dyn StateBackend> = Arc::new(backend);
    let summary = engine
        .apply(&workspace, Arc::clone(&backend_arc), &ws.id, &plan)
        .await?;

    // Complete run
    let status = if summary.failed == 0 {
        "succeeded"
    } else {
        "failed"
    };
    let total_succeeded = (summary.added + summary.changed + summary.destroyed) as i32;
    backend_arc
        .complete_run(&run_id, status, total_succeeded, summary.failed as i32)
        .await?;

    engine.shutdown().await?;

    // Print summary
    println!();
    println!("{}", summary);

    Ok(())
}

async fn cmd_destroy(cli: &Cli, _targets: &[String], auto_approve: bool) -> Result<()> {
    let workspace = loader::load_workspace(Path::new(&cli.config))?;
    let backend = open_backend(&cli.working_dir)?;
    backend.initialize().await?;

    let ws = backend
        .get_workspace(DEFAULT_WORKSPACE)
        .await?
        .context("No default workspace. Run 'oxid init' first.")?;

    // Show what will be destroyed
    let resource_count = backend.count_resources(&ws.id).await?;
    if resource_count == 0 {
        println!("{}", "No resources in state. Nothing to destroy.".dimmed());
        return Ok(());
    }

    // List resources that will be destroyed
    let resources = backend
        .list_resources(&ws.id, &crate::state::models::ResourceFilter::default())
        .await?;

    println!("\nDestruction Plan");
    println!("{}", "─".repeat(60));
    for r in &resources {
        println!("  {} {}", "-".red().bold(), r.address.red());
    }
    println!("{}", "─".repeat(60));
    println!(
        "\n{} This will destroy {} resource(s).",
        "⚠".yellow().bold(),
        resource_count.to_string().red().bold()
    );

    if !auto_approve {
        println!(
            "\nDo you really want to destroy all resources? Only '{}' will be accepted.",
            "yes".bold()
        );
        print!("  Enter a value: ");
        use std::io::Write;
        std::io::stdout().flush()?;
        let mut input = String::new();
        std::io::stdin().read_line(&mut input)?;
        if input.trim() != "yes" {
            println!("\n{}", "Destroy cancelled.".yellow());
            return Ok(());
        }
    }

    let pm = Arc::new(provider_manager(&cli.working_dir));
    let engine = ResourceEngine::new(pm, cli.parallelism);

    let run_id = backend
        .start_run(&ws.id, "destroy", resource_count as i32)
        .await?;

    let backend_arc: Arc<dyn StateBackend> = Arc::new(backend);
    let summary = engine
        .destroy(&workspace, Arc::clone(&backend_arc), &ws.id)
        .await?;

    let status = if summary.failed == 0 {
        "succeeded"
    } else {
        "failed"
    };
    backend_arc
        .complete_run(
            &run_id,
            status,
            summary.destroyed as i32,
            summary.failed as i32,
        )
        .await?;

    engine.shutdown().await?;

    // Print summary
    println!();
    println!("{}", summary);

    Ok(())
}

async fn cmd_state(cli: &Cli, command: &StateCommands) -> Result<()> {
    let backend = open_backend(&cli.working_dir)?;
    backend.initialize().await?;

    let ws = backend
        .get_workspace(DEFAULT_WORKSPACE)
        .await?
        .context("No default workspace. Run 'oxid init' first.")?;

    match command {
        StateCommands::List { filter } => {
            let resource_filter = if let Some(f) = filter {
                // Parse filter like "type=aws_vpc" or "status=created"
                let mut rf = ResourceFilter::default();
                for part in f.split(',') {
                    let kv: Vec<&str> = part.splitn(2, '=').collect();
                    if kv.len() == 2 {
                        match kv[0].trim() {
                            "type" => rf.resource_type = Some(kv[1].trim().to_string()),
                            "module" => rf.module_path = Some(kv[1].trim().to_string()),
                            "status" => rf.status = Some(kv[1].trim().to_string()),
                            _ => {}
                        }
                    }
                }
                rf
            } else {
                ResourceFilter::default()
            };

            let resources = backend.list_resources(&ws.id, &resource_filter).await?;
            output::formatter::print_resource_list(&resources);
        }

        StateCommands::Show { address } => {
            let resource = backend
                .get_resource(&ws.id, address)
                .await?
                .context(format!("Resource '{}' not found in state.", address))?;
            output::formatter::print_resource_detail(&resource);
        }

        StateCommands::Rm { address } => {
            let resource = backend.get_resource(&ws.id, address).await?;
            if resource.is_none() {
                bail!("Resource '{}' not found in state.", address);
            }
            backend.delete_resource(&ws.id, address).await?;
            output::formatter::print_success(&format!(
                "Removed {} from state (infrastructure unchanged).",
                address
            ));
        }

        StateCommands::Mv {
            source,
            destination,
        } => {
            let resource = backend
                .get_resource(&ws.id, source)
                .await?
                .context(format!("Source resource '{}' not found in state.", source))?;

            // Check destination doesn't exist
            if backend.get_resource(&ws.id, destination).await?.is_some() {
                bail!(
                    "Destination resource '{}' already exists in state.",
                    destination
                );
            }

            // Create at new address, delete old
            let mut moved = resource.clone();
            moved.address = destination.clone();
            moved.id = uuid::Uuid::new_v4().to_string();
            moved.updated_at = chrono::Utc::now().to_rfc3339();
            backend.upsert_resource(&moved).await?;
            backend.delete_resource(&ws.id, source).await?;

            output::formatter::print_success(&format!("Moved {} → {}", source, destination));
        }
    }

    Ok(())
}

async fn cmd_import(cli: &Cli, command: &ImportCommands) -> Result<()> {
    let backend = open_backend(&cli.working_dir)?;
    backend.initialize().await?;

    let ws = backend
        .get_workspace(DEFAULT_WORKSPACE)
        .await?
        .context("No default workspace. Run 'oxid init' first.")?;

    match command {
        ImportCommands::Tfstate { path } => {
            let state_json = std::fs::read_to_string(path)
                .context(format!("Failed to read tfstate file: {}", path))?;

            let result = backend.import_tfstate(&ws.id, &state_json).await?;

            println!();
            println!("{}", "Import Results".bold().cyan());
            println!("{}", "─".repeat(40));
            println!(
                "  {} {}",
                "Imported:".bold(),
                result.imported.to_string().green()
            );
            println!(
                "  {} {}",
                "Skipped:".bold(),
                result.skipped.to_string().yellow()
            );
            if !result.warnings.is_empty() {
                println!("  {}:", "Warnings".bold().yellow());
                for w in &result.warnings {
                    println!("    {} {}", "!".yellow(), w);
                }
            }
            println!();
        }

        ImportCommands::Resource { address, id } => {
            // Parse address to get resource type
            let parts: Vec<&str> = address.splitn(2, '.').collect();
            if parts.len() != 2 {
                bail!(
                    "Invalid resource address '{}'. Expected format: type.name",
                    address
                );
            }
            let resource_type = parts[0];
            let resource_name = parts[1];

            let workspace = loader::load_workspace(Path::new(&cli.config))?;

            // Find the provider for this resource type
            let provider_prefix = resource_type.split('_').next().unwrap_or(resource_type);
            let provider_source = workspace
                .providers
                .iter()
                .find(|p| p.name == provider_prefix || p.source.contains(provider_prefix))
                .map(|p| p.source.clone())
                .context(format!(
                    "No provider found for resource type '{}'",
                    resource_type
                ))?;

            let pm = Arc::new(provider_manager(&cli.working_dir));
            let engine = ResourceEngine::new(pm, cli.parallelism);

            // Use the provider's ImportResourceState RPC
            // For now, create a resource state entry with the provider ID
            let mut resource = ResourceState::new(&ws.id, resource_type, resource_name, address);
            resource.provider_source = provider_source;
            resource.status = "created".to_string();
            resource.attributes_json = serde_json::json!({ "id": id }).to_string();

            backend.upsert_resource(&resource).await?;
            engine.shutdown().await?;

            output::formatter::print_success(&format!("Imported {} (id: {}).", address, id));
        }
    }

    Ok(())
}

async fn cmd_query(cli: &Cli, sql: &str, format: &str) -> Result<()> {
    let backend = open_backend(&cli.working_dir)?;
    backend.initialize().await?;

    let fmt = QueryFormat::from_str(format);
    let result = execute_query(&backend, sql, fmt).await?;
    println!("{}", result);
    Ok(())
}

async fn cmd_workspace(cli: &Cli, command: &WorkspaceCommands) -> Result<()> {
    let backend = open_backend(&cli.working_dir)?;
    backend.initialize().await?;

    match command {
        WorkspaceCommands::List => {
            let workspaces = backend.list_workspaces().await?;
            if workspaces.is_empty() {
                println!("{}", "No workspaces.".dimmed());
                return Ok(());
            }
            println!();
            println!("{}", "Workspaces".bold().cyan());
            println!("{}", "─".repeat(40));
            for ws in &workspaces {
                let marker = if ws.name == DEFAULT_WORKSPACE {
                    "*".green().to_string()
                } else {
                    " ".to_string()
                };
                println!(" {} {}", marker, ws.name.bold());
            }
            println!();
        }

        WorkspaceCommands::New { name } => {
            if backend.get_workspace(name).await?.is_some() {
                bail!("Workspace '{}' already exists.", name);
            }
            backend.create_workspace(name).await?;
            output::formatter::print_success(&format!("Created workspace '{}'.", name));
        }

        WorkspaceCommands::Select { name } => {
            backend
                .get_workspace(name)
                .await?
                .context(format!("Workspace '{}' not found.", name))?;
            // Write selected workspace to a file
            let ws_file = format!("{}/.workspace", cli.working_dir);
            std::fs::write(&ws_file, name)?;
            output::formatter::print_success(&format!("Switched to workspace '{}'.", name));
        }

        WorkspaceCommands::Delete { name } => {
            if name == DEFAULT_WORKSPACE {
                bail!("Cannot delete the default workspace.");
            }
            backend
                .get_workspace(name)
                .await?
                .context(format!("Workspace '{}' not found.", name))?;
            backend.delete_workspace(name).await?;
            output::formatter::print_success(&format!("Deleted workspace '{}'.", name));
        }
    }

    Ok(())
}

async fn cmd_graph(cli: &Cli, graph_type: &str) -> Result<()> {
    let workspace = loader::load_workspace(Path::new(&cli.config))?;

    match graph_type {
        "resource" => {
            let provider_map = executor::engine::build_provider_map(&workspace);
            let (graph, _) = dag::resource_graph::build_resource_dag(&workspace, &provider_map)?;
            let dot = dag::resource_graph::to_dot(&graph);
            println!("{}", dot);
        }
        "module" => {
            // Fall back to the legacy module-level DAG for YAML configs
            let cfg = config::parser::load_config(&cli.config)?;
            let graph = dag::builder::build_dag(&cfg)?;
            let dot = dag::visualizer::to_dot(&graph);
            println!("{}", dot);
        }
        _ => bail!(
            "Unknown graph type '{}'. Use 'resource' or 'module'.",
            graph_type
        ),
    }

    Ok(())
}

async fn cmd_providers(cli: &Cli) -> Result<()> {
    let backend = open_backend(&cli.working_dir)?;
    backend.initialize().await?;

    let ws = backend
        .get_workspace(DEFAULT_WORKSPACE)
        .await?
        .context("No default workspace. Run 'oxid init' first.")?;

    let providers = backend.list_providers(&ws.id).await?;

    if providers.is_empty() {
        // Try loading from config
        match loader::load_workspace(Path::new(&cli.config)) {
            Ok(workspace) if !workspace.providers.is_empty() => {
                println!();
                println!("{}", "Configured Providers".bold().cyan());
                println!("{}", "─".repeat(50));
                for p in &workspace.providers {
                    let version = p.version_constraint.as_deref().unwrap_or("any");
                    println!(
                        "  {} {} {}",
                        "→".blue(),
                        p.source.bold(),
                        format!("({})", version).dimmed()
                    );
                }
                println!();
                println!("{}", "Run 'oxid init' to download providers.".dimmed());
            }
            _ => {
                println!("{}", "No providers configured.".dimmed());
            }
        }
        return Ok(());
    }

    println!();
    println!("{}", "Installed Providers".bold().cyan());
    println!("{}", "─".repeat(50));
    for (_id, source, version) in &providers {
        println!(
            "  {} {} {}",
            "✓".green(),
            source.bold(),
            format!("v{}", version).dimmed()
        );
    }
    println!();

    Ok(())
}

async fn cmd_drift(cli: &Cli, refresh: bool) -> Result<()> {
    let workspace = loader::load_workspace(Path::new(&cli.config))?;
    let backend = open_backend(&cli.working_dir)?;
    backend.initialize().await?;

    let ws = backend
        .get_workspace(DEFAULT_WORKSPACE)
        .await?
        .context("No default workspace. Run 'oxid init' first.")?;

    if refresh {
        println!("{}", "Refreshing state from providers...".dimmed());
        let pm = Arc::new(provider_manager(&cli.working_dir));
        let engine = ResourceEngine::new(pm, cli.parallelism);

        // Initialize providers
        for provider in &workspace.providers {
            let version = provider.version_constraint.as_deref().unwrap_or(">= 0.0.0");
            let _ = engine
                .provider_manager()
                .get_connection(&provider.source, version)
                .await;
        }

        // Read each resource from the provider and update state
        let resources = backend
            .list_resources(&ws.id, &ResourceFilter::default())
            .await?;
        let mut refreshed = 0;
        for resource in &resources {
            if resource.provider_source.is_empty() {
                continue;
            }
            let current: serde_json::Value =
                serde_json::from_str(&resource.attributes_json).unwrap_or_default();
            match engine
                .provider_manager()
                .read_resource(&resource.provider_source, &resource.resource_type, &current)
                .await
            {
                Ok(Some(refreshed_state)) => {
                    let mut updated = resource.clone();
                    updated.attributes_json = serde_json::to_string(&refreshed_state)?;
                    updated.updated_at = chrono::Utc::now().to_rfc3339();
                    backend.upsert_resource(&updated).await?;
                    refreshed += 1;
                }
                Ok(None) => {
                    // Resource no longer exists
                    println!(
                        "  {} {} — {}",
                        "-".red(),
                        resource.address.bold(),
                        "resource no longer exists".red()
                    );
                }
                Err(e) => {
                    tracing::warn!(
                        address = %resource.address,
                        error = %e,
                        "Failed to refresh resource"
                    );
                }
            }
        }

        engine.shutdown().await?;
        if refreshed > 0 {
            println!("  {} Refreshed {} resource(s).\n", "✓".green(), refreshed);
        }
    }

    // Compare config vs state for drift
    let resources = backend
        .list_resources(&ws.id, &ResourceFilter::default())
        .await?;

    // Resources in config
    let config_addresses: std::collections::HashSet<String> = workspace
        .resources
        .iter()
        .map(|r| format!("{}.{}", r.resource_type, r.name))
        .collect();

    // Resources in state
    let state_addresses: std::collections::HashSet<String> =
        resources.iter().map(|r| r.address.clone()).collect();

    let mut drifts = Vec::new();

    // New in config, not in state
    for addr in config_addresses.difference(&state_addresses) {
        drifts.push(("+", addr.clone(), "new resource in config"));
    }

    // In state, not in config
    for addr in state_addresses.difference(&config_addresses) {
        drifts.push(("-", addr.clone(), "in state but not in config"));
    }

    if drifts.is_empty() {
        output::formatter::print_success("No drift detected. Infrastructure is in sync.");
    } else {
        println!();
        println!(
            "{}",
            format!("Drift Detected ({} issues)", drifts.len())
                .bold()
                .yellow()
        );
        println!("{}", "─".repeat(60));
        for (icon, addr, detail) in &drifts {
            let colored_icon = match *icon {
                "+" => "+".green().to_string(),
                "-" => "-".red().to_string(),
                "~" => "~".yellow().to_string(),
                _ => icon.to_string(),
            };
            println!("  {} {} {}", colored_icon, addr.bold(), detail.dimmed());
        }
        println!("{}", "─".repeat(60));
        println!();
    }

    Ok(())
}

async fn cmd_validate(cli: &Cli) -> Result<()> {
    let config_path = Path::new(&cli.config);
    let mode = loader::detect_mode(config_path);

    println!("  {} Config format: {:?}", "→".blue(), mode);

    let workspace = loader::load_workspace(config_path)?;

    println!(
        "  {} {} provider(s), {} resource(s), {} data source(s), {} module(s), {} variable(s), {} output(s)",
        "→".blue(),
        workspace.providers.len(),
        workspace.resources.len(),
        workspace.data_sources.len(),
        workspace.modules.len(),
        workspace.variables.len(),
        workspace.outputs.len(),
    );

    // Validate provider sources
    for provider in &workspace.providers {
        if provider.source.is_empty() {
            bail!("Provider '{}' has empty source.", provider.name);
        }
    }

    // Validate resource types
    for resource in &workspace.resources {
        if resource.resource_type.is_empty() {
            bail!("Resource '{}' has empty type.", resource.name);
        }
    }

    // Validate depends_on references
    let all_addresses: std::collections::HashSet<String> = workspace
        .resources
        .iter()
        .map(|r| format!("{}.{}", r.resource_type, r.name))
        .collect();

    for resource in &workspace.resources {
        for dep in &resource.depends_on {
            if !all_addresses.contains(dep) {
                tracing::warn!(
                    resource = format!("{}.{}", resource.resource_type, resource.name),
                    depends_on = %dep,
                    "depends_on references unknown resource"
                );
            }
        }
    }

    output::formatter::print_success("Configuration is valid.");
    Ok(())
}
